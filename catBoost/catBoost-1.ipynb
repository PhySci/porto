{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ecf01439-91f9-40c2-90ca-cfc9fef897f9",
    "_uuid": "663762d0acd501a442290010ddc25eaea219ff13"
   },
   "source": [
    "Based on [olivier's script](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "45ba73d4-6c4c-40bb-9390-7dfc956c555d",
    "_uuid": "dbd332f83c89108c4e641218f5c4e7b9cd325b80"
   },
   "outputs": [],
   "source": [
    "EARLY_STOPPING_ROUNDS = 50  \n",
    "# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n",
    "#       I will get lots of information to make my own judgment.  You should probably\n",
    "#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e199c98-16b0-45e7-a6d1-bdd9325c2631",
    "_uuid": "b277fe426336d65ac71f0e6ac96c7ee16d02074c"
   },
   "source": [
    "I recommend initially setting <code>MAX_ROUNDS</code> fairly high and using <code>OPTIMIZE_ROUNDS</code> to get an idea of the appropriate number of rounds (which, in my judgment, should be close to the maximum value of  <code>best_ntree_limit</code> among all folds, maybe even a bit higher if your model is adequately regularized...or alternatively, you could set <code>verbose=True</code> and look at the details to try to find a number of rounds that works well for all folds).  Then I would turn off <code>OPTIMIZE_ROUNDS</code> and set <code>MAX_ROUNDS</code> to the appropraite number of total rounds.  \n",
    "\n",
    "The problem with \"early stopping\" by choosing the best round for each fold is that it overfits to the validation data.    It's therefore liable not to produce the optimal model for predicting test data, and if it's used to produce validation data for stacking/ensembling with other models, it would cause this one to have too much weight in the ensemble.  Another possibility (and the default for XGBoost, it seems) is to use the round where the early stop actually happens (with the lag that verifies lack of improvement) rather than the best round.  That solves the overfitting problem (provided the lag is long enough), but so far it doesn't seem to have helped.  (I got a worse validation score with 20-round early stopping per fold than with a constant number of rounds for all folds, so the early stopping actually seemed to underfit.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "b7258128-55f9-4543-8611-5e0a6661837b",
    "_uuid": "72171ee53e170096d37a18eef84682fa348ae5c4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "3d16f16e-12cc-4b41-b7bd-fa05ce44770c",
    "_uuid": "154b078a7e86c0a5a328118a61d28e2581bb3b0a"
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "99b88ea4-a9af-45aa-9df0-86412d7264cf",
    "_uuid": "67a8ca9dead7110c776d7f75bb8963b3429617cb"
   },
   "outputs": [],
   "source": [
    "# Functions from olivier's kernel\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(series.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "        # from olivier\n",
    "    train_features = [\n",
    "        \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "        \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "        \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "        \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "        \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "        \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "        \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "        \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "        \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "        \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "        \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "        \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "        \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "        \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "        \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "        \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "        \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "        \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "        \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "        \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "        \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "        \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "        \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "        \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "        \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "        \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "        \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "        \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "        \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "        \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "        \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "        \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "        \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "        \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "    ]\n",
    "    \n",
    "    # Read data\n",
    "    train_df = pd.read_csv('../data/train.csv', index_col='id') # .iloc[0:200,:]\n",
    "    test_df = pd.read_csv('../data/test.csv', index_col='id')\n",
    "    \n",
    "    train_df = train_df.loc[:, train_features + [\"target\"]]\n",
    "    test_df  = test_df.loc[:,train_features]\n",
    "    return [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class featureCombination:\n",
    "    \"\"\"\n",
    "    Class provide usual \"fit-tranform\" functionality for feature combinations \n",
    "    \"\"\"\n",
    "    def __init__(self, combinationList):\n",
    "        self.comninationList = combinationList\n",
    "        self.encoders = dict()\n",
    "    \n",
    "    def fit_transform(self,df):\n",
    "        X = df.copy() \n",
    "        \n",
    "        for n_c, (f1, f2) in enumerate(self.comninationList):\n",
    "            fName = f1 + \"_plus_\" + f2\n",
    "            # add new feature\n",
    "            X.insert(X.shape[1], fName, X[f1].astype('str')+\"_\"+X[f2].astype('str'))\n",
    "                     \n",
    "            # encode new feature         \n",
    "            lbl = LabelEncoder()\n",
    "            X[fName] = lbl.fit_transform(X[fName])\n",
    "            self.encoders.update({fName:lbl})\n",
    "               \n",
    "        return X\n",
    "    \n",
    "    def transform(self,df):\n",
    "        X = df.copy() \n",
    "        \n",
    "        for n_c, (f1, f2) in enumerate(self.comninationList):\n",
    "            fName = f1 + \"_plus_\" + f2\n",
    "            # add new feature\n",
    "            X.insert(X.shape[1], fName, X[f1].astype('str')+\"_\"+X[f2].astype('str'))\n",
    "                     \n",
    "            # encode new feature         \n",
    "            lbl = self.encoders.get(fName)\n",
    "            X[fName] = lbl.fit_transform(X[fName])\n",
    "            self.encoders.update({fName:lbl})\n",
    "               \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class targetEncode():\n",
    "    \n",
    "    \n",
    "    def __init__(self, features, min_samples_leaf=1, smoothing=1, fillna = True):\n",
    "        self.suffix = '_tarEncd'\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        self.min_samples_leaf = 1\n",
    "        self.smoothing = smoothing\n",
    "        \n",
    "        self.encoders = dict()\n",
    "        self.prior = 1.0\n",
    "        self.fillna = fillna\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, inpDf, targetColumn = 'target'):\n",
    "        \"\"\"\n",
    "        Fit to features and transform them\n",
    "        params:\n",
    "            df - dataframe to process\n",
    "            targetColumn  - name of columns which will be used as a target variable \n",
    "        \"\"\"\n",
    "\n",
    "        for colName in self.features:\n",
    "            \n",
    "            if not (colName in inpDf.columns):\n",
    "                raise Exception('Columns name mismatch', 'Column %s was not found in dataframe'%colName)\n",
    "            \n",
    "            self.prior = inpDf[targetColumn].mean()\n",
    "            averages = inpDf.groupby(by= colName)[targetColumn].agg([\"mean\", \"count\"])\n",
    "            smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - self.min_samples_leaf) / self.smoothing))\n",
    "            averages['target'] = self.prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "            self.encoders.update({colName: averages.to_dict(orient= 'dict')['target']})\n",
    "            \n",
    "        return self.transform(inpDf)\n",
    "    \n",
    "    def transform(self, inpDf):\n",
    "        \"\"\"\n",
    "        Transform features\n",
    "        params:\n",
    "            df - dataframe to process\n",
    "        \"\"\"\n",
    "        \n",
    "        df = inpDf.copy()    \n",
    "        for colName in self.features:\n",
    "            if colName+self.suffix in df.columns:\n",
    "                df.drop(colName+self.suffix, axis = 1, inplace= True)\n",
    "            \n",
    "            ts = df[colName].map(self.encoders[colName], na_action= 'ignore')\n",
    "            \n",
    "            if self.fillna:\n",
    "                ts.fillna(self.prior, inplace = True)\n",
    "            \n",
    "            df.insert(df.shape[1], colName+self.suffix, ts)\n",
    "        return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "def getModel(params,seed = 43, dirName = '.'):\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(predDf, fName = 'submission.csv'):\n",
    "    \"\"\"\n",
    "    Write submission file.\n",
    "    params:\n",
    "        pred - predictions (array)\n",
    "        ind - index for prediction (array)\n",
    "        fName - name of file (string)\n",
    "    \"\"\"\n",
    "    predDf.rename(columns={'prediction':'target'},inplace=True)\n",
    "    predDf.to_csv(fName,index_label='id',float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCatBoost(params, varSeed= True, folds= 5, encode_target= True):\n",
    "    \n",
    "    dirName= '/tmp/porto/catboost/'\n",
    "    \n",
    "    treeList = list()\n",
    "    scoreList = list()\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(dirName)\n",
    "    except Exception as inst:\n",
    "        print inst  # __str__ allows args to be printed directly\n",
    "    # Run CV\n",
    "    localScore = []\n",
    "    \n",
    "    valDf = pd.DataFrame(0, index = train_df.index, columns = ['fold','prediction'])\n",
    "    testDf = pd.DataFrame(0, index = test_df.index, columns = ['prediction'])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(train_df.drop(\"target\", axis= 1), train_df.target)):\n",
    "\n",
    "        print \"\\nFold \", i\n",
    "\n",
    "        # Create data for this fold\n",
    "        if encode_target:\n",
    "            te = targetEncode(features= f_cats, min_samples_leaf= 200, smoothing= 100)\n",
    "            X_train = te.fit_transform(train_df.iloc[train_index,:])\n",
    "            X_valid = te.transform(train_df.iloc[test_index,:])\n",
    "            X_test  = te.transform(test_df)\n",
    "        else:\n",
    "            X_train = train_df.iloc[train_index,:]\n",
    "            X_valid = train_df.iloc[test_index,:]\n",
    "            X_test  = test_df\n",
    "        \n",
    "        trainPool = Pool(X_train.drop('target', axis = 1), X_train.target)\n",
    "        valPool   = Pool(X_valid.drop('target', axis = 1), X_valid.target)\n",
    "        testPool  = Pool(X_test)\n",
    "        \n",
    "        model = CatBoostClassifier(train_dir= dirName +\"/\"+ str(seed),\n",
    "                                   random_seed= i if varSeed else 0,\n",
    "                                   **params)\n",
    "        \n",
    "        model.fit(trainPool,eval_set=valPool, use_best_model=True)    \n",
    "            \n",
    "        # Generate validation predictions for this fold\n",
    "        pred = model.predict_proba(X_valid.drop(\"target\", axis= 1))[:,1]\n",
    "        valDf.prediction.iloc[test_index] = pred\n",
    "        valDf.fold.iloc[test_index] = i\n",
    "\n",
    "        ls = 2*roc_auc_score(X_valid.target, pred)-1\n",
    "        scoreList.append(ls)\n",
    "        treeList.append(model.tree_count_)\n",
    "\n",
    "        print \"  Best N trees = \", model.tree_count_\n",
    "        print \"  Validation score is %f\"%ls\n",
    "\n",
    "        testDf['prediction']+= model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    testDf['prediction'] /= folds  # Average test set predictions\n",
    "    localScore =np.array(scoreList)\n",
    "\n",
    "    print \"\\nGini for full training set (AUC): %f\"%(2*roc_auc_score(train_df.target, valDf.prediction)-1)\n",
    "    print \"\\nAverage validation score is %f, std is %f\"%(localScore.mean(), localScore.std())\n",
    "        \n",
    "    return {'test_prediction': testDf,\n",
    "            'localScore': scoreList,\n",
    "            'train_prediction': valDf,\n",
    "             'trees_number': np.array(treeList),\n",
    "             'params':params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "52b50086-b405-4598-b11c-97887cdcce8e",
    "_uuid": "07a5a5782894611e9006ae1b399b0b8fb8a0f06b"
   },
   "outputs": [],
   "source": [
    "[train_df, test_df] = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "d9a217fa-50f4-43a7-805b-d1c796a7ebf7",
    "_uuid": "da09aaf7c0c77a131c7d9d53feae512c8f9730c1"
   },
   "outputs": [],
   "source": [
    "# add combinations\n",
    "combs = [('ps_reg_01', 'ps_car_02_cat'),  \n",
    "         ('ps_reg_01', 'ps_car_04_cat')]\n",
    "\n",
    "fComb = featureCombination(combs)\n",
    "\n",
    "train_df = fComb.fit_transform(train_df)\n",
    "test_df = fComb.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cats = [x for x in test_df.columns if x.endswith('_cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "c4e48347-920f-4ba7-8b37-cfbaab4c3c00",
    "_uuid": "2b9ed96c98b705d3e4bf2a3d60323dfab4332674",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbParams = {'verbose': False,\n",
    "            'iterations': 5000,\n",
    "            'eval_metric': \"AUC\",\n",
    "            'depth': 7,\n",
    "            'learning_rate': 0.055,\n",
    "            'l2_leaf_reg': 5.5,\n",
    "            'bagging_temperature': 1.5,\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': 100,\n",
    "            'gradient_iterations': 4,\n",
    "            'rsm':0.9}            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/tmp/porto/catboost/'\n",
      "\n",
      "Fold  0\n",
      "  Best N trees =  494\n",
      "  Validation score is 0.269920\n",
      "\n",
      "Fold  1\n",
      "  Best N trees =  509\n",
      "  Validation score is 0.291669\n",
      "\n",
      "Fold  2\n",
      "  Best N trees =  521\n",
      "  Validation score is 0.285490\n",
      "\n",
      "Fold  3\n",
      "  Best N trees =  516\n",
      "  Validation score is 0.292098\n",
      "\n",
      "Fold  4\n",
      "  Best N trees =  416\n",
      "  Validation score is 0.287579\n",
      "\n",
      "Gini for full training set (AUC): 0.285305\n",
      "\n",
      "Average validation score is 0.285351, std is 0.008106\n"
     ]
    }
   ],
   "source": [
    "model1 = trainCatBoost(cbParams, encode_target= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public LN sccore is 0.281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/tmp/porto/catboost/'\n",
      "\n",
      "Fold  0\n",
      "  Best N trees =  586\n",
      "  Validation score is 0.267253\n",
      "\n",
      "Fold  1\n",
      "  Best N trees =  601\n",
      "  Validation score is 0.289652\n",
      "\n",
      "Fold  2\n",
      "  Best N trees =  454\n",
      "  Validation score is 0.285142\n",
      "\n",
      "Fold  3\n",
      "  Best N trees =  507\n",
      "  Validation score is 0.288190\n",
      "\n",
      "Fold  4\n",
      "  Best N trees =  311\n",
      "  Validation score is 0.285797\n",
      "\n",
      "Gini for full training set (AUC): 0.283051\n",
      "\n",
      "Average validation score is 0.283207, std is 0.008141\n"
     ]
    }
   ],
   "source": [
    "model2 = trainCatBoost(cbParams, encode_target= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public LB score is 0.279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catbModel1.dmp']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model1,'catbModel1.dmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catModel2.dmp']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model2,'catModel2.dmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(model1['test_prediction'],'cat1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(model2['test_prediction'],'cat2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробовать оптимизацию параметров для использованного набора фич и пайплайна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels.dmp']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_df.target,'labels.dmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Machine Learning)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
